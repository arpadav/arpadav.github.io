<!doctype html><meta content="text/html; charset=utf-8"charset=utf-8 http-equiv=Content-Type><title>Semantic Segmentation of Crop Damage - Arpad Voros</title><link href=/images/site.webmanifest rel=manifest><link href=/images/favicon-16x16.png rel=icon sizes=16x16 type=image/png><link href=/images/favicon-32x32.png rel=icon sizes=32x32 type=image/png><link href=/images/apple-touch-icon.png rel=apple-touch-icon sizes=180x180><script src="https://www.googletagmanager.com/gtag/js?id=G-8RV0KPZZXQ"async></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[];gtag(`js`,new Date());gtag(`config`,`G-8RV0KPZZXQ`)</script></head><div class=sidebar id=sidebar><li><a href=/gator/ target=_parent> <img src=/images/alligator.png style=width:268px> </a><li>   <h3><b> personal</b></h3>      <li><a href=/projects/2022f_lang/ target=_parent> <i>Vocabulary-emphasized Language Learning Application using no 'Reference' Language</i> </a><li>§<li><a href=/projects/2020t_website/ target=_parent> <i>Personal Website — arpadav.github.io (hosted on arpadvoros.com)</i> </a><li>§<li><a href=/projects/2019t_plotter/ target=_parent> <i>Physical Plotting Output of Generative Adversarial Network Trained on Landscape Portraits</i> </a><li>§<li><a href=/projects/2018s_mra/ target=_parent> <i>Google Hangouts Chat-bot and iOS 'Alert' Application</i> </a><li>§<li><a href=/projects/2018f_theremin/ target=_parent> <i>Moog Theremin</i> </a><li>§<li><a href=/projects/2017f_mst/ target=_parent> <i>Muon Scattering Tomography: Utilizing Silicon Photomultiplier Arrays to Trilaterate Muon Multiple-Coulomb Scattering Events</i> </a><li>   <h3><b> rust crates</b></h3>      <li><a href=/projects/2024t_tinyklv/ target=_parent> <i>tinyklv: A KLV (Key-Length-Value) parser and generator for Rust</i> </a><li>§<li><a href=/projects/2024t_misb/ target=_parent> <i>misb: MISB Standards implementation in Rust</i> </a><li>§<li><a href=/projects/2024s_thisenum/ target=_parent> <i>thisenum: Assigning constants to enum arms</i> </a><li>§<li><a href=/projects/2024s_dted2/ target=_parent> <i>dted2: DTED reader for Rust</i> </a><li>§<li><a href=/projects/2024f_crosstalk/ target=_parent> <i>crosstalk: In-memory pub-sub messaging for Rust</i> </a><li>   <h3><b> academic</b></h3>      <li><a href=/projects/2021t_zsl/ target=_parent> <i>Analysis and Implementation of a Semantic Auto-Encoder for Zero-Short Learning</i> </a><li>§<li><a href=/projects/2021t_dimg/ target=_parent> <i>Digital Imaging — Scale-invariant Feature Transform, Laplacian Blending, Linear Spatial Filtering, and more...</i> </a><li>§<li><a href=/projects/2021f_vader/ target=_parent> <i>Senior Design — Directional Acoustic Deterrence of Elephants to Prevent Human-Elephant Conflict in sub-Saharan Africa</i> </a><li>§<li><a href=/projects/2021f_cvis/ target=_parent> <i>Computer Vision — Facial Recognition using Gaussian Mixture Models, Adaboost & Haar Features, and more...</i> </a><li>§<li><a href=/projects/2020t_terrain/ target=_parent> <i>Terrain Identification using Sensory Prosthetic Limb Timeseries Data</i> </a><li>§<li><a href=/projects/2020t_crop/ target=_parent> <i>Semantic Segmentation of Crop Damage</i> </a><li>§<li><a href=/projects/2020f_hybrid/ target=_parent> <i>Adjusting Hybrid-Energy Model of Photovoltaic Generators to fit Klucher Weather Model</i> </a><li>§<li><a href=/projects/2018s_nedm/ target=_parent> <i>Undergraduate Research for Intercollegiate Search for the Neutron Electric Dipole-Moment</i> </a><li>   <h3><b> mini projects</b></h3>      <li><a href=/projects/2023t_cgol/ target=_parent> <i>Conway's Game of Life using Rust + WASM</i> </a><li>§<li><a href=/projects/2017t_gdax/ target=_parent> <i>High School - Cryptocurrency Trading Bot</i> </a></div><div class=beside-sidebar><div class=navbar id=navbar><ul><li><a href=/# target=_parent>home</a><li><a href=/#about target=_parent>about</a><li><a href=/#contact target=_parent>contact</a><li><a href=/#socials target=_parent>socials</a><li><a href=/cv.pdf target=_parent>cv</a><li><a href=/projects target=_parent>projects</a><li><a href=/notes target=_parent>notes</a></ul></div><div class=project-body><h3>Semantic Segmentation of Crop Damage</h3><i><p>  ECE 542 (Neural Networks) Project 2</i><hr><h4>  Group Project (3 members)* — (See My Contribution) — <i><span style=font-weight:400>Status:</span> Complete</i></h4><p>  <b>Oct 2020 - Nov 2020</b>    — <i>Raleigh, North Carolina</i><hr><p><i>Overview:</i><p>The goal of this project was to process aerial-view images of crops from NCSUs agricultural department, and use a deep learning model to process and use semantic segmentation in classifying areas of crop damage. The metric used for performance evaluation of the model was a mean IOU of the prediction within the validation set. This was a project for ECE 542.<div class=card><img class=center src=/projects/2020t_crop/crop_pred.png style=max-width:250px><h2>====></h2><img class=center src=/projects/2020t_crop/crop.png style=max-width:250px></div><img class=center src=/projects/2020t_crop/unet.png style=max-width:600px><br><p>Shown above: example prediction and U-Net architecture used for performing semantic segmentation.<hr><p><i>My Contribution:</i><p>Group Project (3 members)<p>I worked with the same group as I did in <a href=/projects/2020t_terrain>Terrain Identification using Sensory Prosthetic Limb Timeseries Data</a>.<p>The training images were extremely high resolution, so I made a MATLAB script to downsize all aerial images as well as their respective crop-damage annotations to various sizes. I created multiple U-Net architectures in Keras to perform this semantic segmentation and trained a couple models for each resolution. As expected, models trained on the highest resolution photographs as well as the lowest resolution resamples performed the worst, since there is an expected trade-off between model speed/size and resolution/detail of the photographs. I also created a script to extract intermittent layers of the model to understand why and how the model was working.<p>Similar to <a href=/projects/2020t_terrain>Terrain Identification using Sensory Prosthetic Limb Timeseries Data</a>, I unfortunately did a disproportionate amount of the work. Not as bad this time, but I would say I did ~70%.<hr><p><i>Literature:</i><p>Proposal:</p><a href=/notes/academic/2020%20-%20ECE%20542/Voros_Arpad_ECE542_Proj2Proposal.pdf>Voros_Arpad_ECE542_Proj2Proposal.pdf</a><br><p>Report:</p><a href=/notes/academic/2020%20-%20ECE%20542/Voros_Arpad_ECE542_Proj2.pdf>Voros_Arpad_ECE542_Proj2.pdf</a><br><br><iframe class=center height=950 src=/notes/academic/2020%20-%20ECE%20542/Voros_Arpad_ECE542_Proj2.pdf width=60%></iframe><br></div><base target=_top></div><link href=/css/std.css rel=stylesheet>