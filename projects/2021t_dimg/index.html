<!doctype html><meta content="text/html; charset=utf-8" charset=utf-8 http-equiv=Content-Type><title>Digital Imaging — Scale-invariant Feature Transform, Laplacian Blending, Linear Spatial Filtering, and more... - Arpad Voros</title><link href=/images/site.webmanifest rel=manifest><link href=/images/favicon-16x16.png rel=icon sizes=16x16 type=image/png><link href=/images/favicon-32x32.png rel=icon sizes=32x32 type=image/png><link href=/images/apple-touch-icon.png rel=apple-touch-icon sizes=180x180><script src="https://www.googletagmanager.com/gtag/js?id=G-8RV0KPZZXQ" async></script><script>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-8RV0KPZZXQ');</script></head><div class=sidebar id=sidebar><li><a href=/gator/ target=_parent> <img style="width: 268px;" src=/images/alligator.png> </a><li>   <h3><b> personal</b></h3>      <li><a href=/projects/2022f_lang/ target=_parent> <i>Vocabulary-emphasized Language Learning Application using no 'Reference' Language</i> </a><li>§<li><a href=/projects/2020t_website/ target=_parent> <i>Personal Website — arpadav.github.io (hosted on arpadvoros.com)</i> </a><li>§<li><a href=/projects/2019t_plotter/ target=_parent> <i>Physical Plotting Output of Generative Adversarial Network Trained on Landscape Portraits</i> </a><li>§<li><a href=/projects/2018s_mra/ target=_parent> <i>Google Hangouts Chat-bot and iOS 'Alert' Application</i> </a><li>§<li><a href=/projects/2018f_theremin/ target=_parent> <i>Moog Theremin</i> </a><li>§<li><a href=/projects/2017f_mst/ target=_parent> <i>Muon Scattering Tomography: Utilizing Silicon Photomultiplier Arrays to Trilaterate Muon Multiple-Coulomb Scattering Events</i> </a><li>   <h3><b> rust crates</b></h3>      <li><a href=/projects/2024t_tinyklv/ target=_parent> <i>tinyklv: A KLV (Key-Length-Value) parser and generator for Rust</i> </a><li>§<li><a href=/projects/2024t_misb/ target=_parent> <i>misb: MISB Standards implementation in Rust</i> </a><li>§<li><a href=/projects/2024s_thisenum/ target=_parent> <i>thisenum: Assigning constants to enum arms</i> </a><li>§<li><a href=/projects/2024s_dted2/ target=_parent> <i>dted2: DTED reader for Rust</i> </a><li>§<li><a href=/projects/2024f_crosstalk/ target=_parent> <i>crosstalk: In-memory pub-sub messaging for Rust</i> </a><li>   <h3><b> academic</b></h3>      <li><a href=/projects/2021t_zsl/ target=_parent> <i>Analysis and Implementation of a Semantic Auto-Encoder for Zero-Short Learning</i> </a><li>§<li><a href=/projects/2021t_dimg/ target=_parent> <i>Digital Imaging — Scale-invariant Feature Transform, Laplacian Blending, Linear Spatial Filtering, and more...</i> </a><li>§<li><a href=/projects/2021f_vader/ target=_parent> <i>Senior Design — Directional Acoustic Deterrence of Elephants to Prevent Human-Elephant Conflict in sub-Saharan Africa</i> </a><li>§<li><a href=/projects/2021f_cvis/ target=_parent> <i>Computer Vision — Facial Recognition using Gaussian Mixture Models, Adaboost & Haar Features, and more...</i> </a><li>§<li><a href=/projects/2020t_terrain/ target=_parent> <i>Terrain Identification using Sensory Prosthetic Limb Timeseries Data</i> </a><li>§<li><a href=/projects/2020t_crop/ target=_parent> <i>Semantic Segmentation of Crop Damage</i> </a><li>§<li><a href=/projects/2020f_hybrid/ target=_parent> <i>Adjusting Hybrid-Energy Model of Photovoltaic Generators to fit Klucher Weather Model</i> </a><li>§<li><a href=/projects/2018s_nedm/ target=_parent> <i>Undergraduate Research for Intercollegiate Search for the Neutron Electric Dipole-Moment</i> </a><li>   <h3><b> mini projects</b></h3>      <li><a href=/projects/2023t_cgol/ target=_parent> <i>Conway's Game of Life using Rust + WASM</i> </a><li>§<li><a href=/projects/2017t_gdax/ target=_parent> <i>High School - Cryptocurrency Trading Bot</i> </a></div><div class=beside-sidebar><div class=navbar id=navbar><ul><li><a href=/# target=_parent>home</a><li><a href=/#about target=_parent>about</a><li><a href=/#contact target=_parent>contact</a><li><a href=/#socials target=_parent>socials</a><li><a href=/cv.pdf target=_parent>cv</a><li><a href=/projects target=_parent>projects</a><li><a href=/notes target=_parent>notes</a></ul></div><div class=project-body><h3>Digital Imaging — Scale-invariant Feature Transform, Laplacian Blending, Linear Spatial Filtering, and more...</h3><i><p>  ECE 558 (Digital Imaging) Projects</i><hr><h4>  Individual Project — <i><span style=font-weight:normal>Status:</span> Complete</i></h4><p>  <b>Aug 2021 - Dec 2021</b>    — <i>Raleigh, North Carolina</i><hr><p><i>Overview:</i><ol><li><b>Project 1: Linear Spatial Filtering</b></li><ul style="list-style-type: none;"><li><img style="max-width: 1000px" class=center src=/projects/2021t_dimg/p1_lena_prewittx.jpg></li><br><li>The primary application for linear spatial filtering in image processing is usually for applying different distributions of noise, detecting linear signal properties like edges or corners, or detecting 'objects' by performing filtering and using a difference metric to see how disparate the region within the image is to the kernel. In this project, multiple linear operators (Sobel, Roberts, Prewitt, etc.) along with kernels like box & Gaussian were were implemented and tested. Above, you see the original image with the Prewitt operator along the 'x' (horizontal) direction being applied. Respective to each RGB channel, hence the color. After processed, the end result is the leftmost image. Below, the same operator in the 'y' (vertical) direction is applied and the magnitude is calculated on the leftmost image. Below the magnitude along the RGB channels is shown, hence why it is black and white. This is the most common application for these edge detecting operators, as it can be seen how effectively an edge is found.</li><br><li>Implemented in MATLAB, all figures are my own.</li><br><li><img style="max-width: 1000px" class=center src=/projects/2021t_dimg/p1_lena_mag.jpg></li><div class=card><p class=center_desc>x gradient ===> y gradient ===> gradient magntiude</div><br><li>I understand there are social implications / movements within the image processing community to stop using this Lena image, however this was one of the primary images used during this class. More can be read in the report below, see the <i>Literature</i> section.</li><br><li><i>PS: I also did a lot more during all these 3 projects with respect to image processing. Some art may be coming soon :~) — simple / bad examples of what I did w.r.t. LSF + animations are shown below:</i></li><br><li><div class=card><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p0_0.gif><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p0_1.gif><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p0_2.gif><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p0_3.gif></div></ul><br><li><b>Project 2: Laplacian Blending</b></li><ul style="list-style-type: none;"><li>A Gaussian 'pyramid' is essentially an image downsizing technique, where a variable amount of blur (but constant with respect to each 'pyramid') is applied to an image before downsampled. This downsizes the image while maintaining the 'look' of the image. The term 'pyramid' is used as a visualization if each successive downsample was tiled ontop of one another, creating a rectangular pyramid of sorts. A Laplacian pyramid can be approximated using a difference of Gaussian's at two respective blur amounts. This Laplacian pyramid was original made as a form of lossy image compression, where the original image can be reconstructed with a couple low-data Laplacian's that held detail of the image, and one single Gaussian (the lowest size of the pyramid) which held the color composition of the image. It was discovered that images can be blended during this reconstruction process by generating the Gaussian / Laplacian pyramids of two images as well as a mask. During reconstruction, the mask and its inverse is simply multiplied by each respective picture and then expanded. This creates a rudimentary blending effect. There is still room for color and texture correction, and this is why the example images shown blend objects with similar colors and textures. More can be read in the report below, see the <i>Literature</i> section.</li><br><li>Implemented blending and GUI for creating mask in MATLAB, all figures are my own.</li><br><li><div class=card><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p2_cat.jpg><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p2_dogcat.png><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p2_catdog.png><img style="max-width: 200px" class=center src=/projects/2021t_dimg/p2_dog.jpg></div> <img style="max-width: 1000px" class=center src=/projects/2021t_dimg/p2_hand.png></ul><br><li><b>Project 3: Optimized Blob Detection — a Precursor to SIFT Detector</b></li><ul style="list-style-type: none;"><li>A scale-invariant feature transform (SIFT) detector tries to detect features of an image invariant to transformations such as scale, rotation, and translation. The idea behind the SIFT detector is to take an image of some environment at different angles, lighting, etc., and to be able to extract key points within the image that align with both images, despite having some amount of linear relative distortion. The first step in finding these SIFT interest points happens to align with the same task of 'blob detection'. A series of linear spatial filters are applied to an image to detect edges of varying sizes. If an edge happens to be relatively circular + compact, the result constructively creates a 'blob', where the local maxima/minima of these blobs is a SIFT interest point. The size of each blob is a function of the types of filters used, the size of the image, and more.</li><br><li>For this project, there was an optional speed test for extra credit. I did not really need the extra credit, but I had already optimized my script / algorithm to such an extent where I decided go all out and compete. More can be read in the 'Algorithm' section of the report, shown below. I placed first in the competition.<li>More can be read in the report below, see the <i>Literature</i> section.</li><br><li>Implemented in MATLAB, all figures are my own.</li><br><div class=card><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_0.png><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_1.png><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_2.png><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_3.png></div><div class=card><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_7.png><img style="max-width: 350px" class=center src=/projects/2021t_dimg/p3_6.png><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_5.png><img style="max-width: 300px" class=center src=/projects/2021t_dimg/p3_4.png></div></ul></ol><hr><p><i>Personal Statement:</i><p>Fun class. I like pictures.<hr><p><i>Literature:</i></p><a href=/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj1.pdf>Voros_Arpad_ECE558_proj1.pdf</a><br><a href=/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj2.pdf>Voros_Arpad_ECE558_proj2.pdf</a><br><a href=/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj3.pdf>Voros_Arpad_ECE558_proj3.pdf</a><br><br><iframe class=center height=950 src=/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj3.pdf width=60%></iframe><hr><p><i>Media Citation(s):</i><p>Dog and Cat (not blended) - <a href="https://www.google.com/imghp?hl=en">https://www.google.com/imghp?hl=en</a><p>Test images prior to manipulation (Lena, Einstein, peppers, etc.) - <a href=http://www.imageprocessingplace.com/root_files_V3/image_databases.htm>http://www.imageprocessingplace.com/root_files_V3/image_databases.htm</a></p><br></div><base target=_top></div><link href=/css/std.css rel=stylesheet>